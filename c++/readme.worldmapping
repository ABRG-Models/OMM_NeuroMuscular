27th July 2015

Here's a description of how the mappings take you from a description
of luminances in a world, through to a cortical map of neural element
activations.

The luminances are specified in a json file. The file contains an
array of luminances which are specified like this:

      {
        // Single target luminance example. "luminances" is an array.
        "luminances": [
          // This is the fixation luminance:
          {
            "shape":"cross",
            "thetaX":0,
            "thetaY":0,
            "widthThetaX":6,
            "widthThetaY":2,
            "luminance":0.5,
            "timeOn":0.0,
            "timeOff":0.050
          },
          // Here's the target luminance (because it comes on after
          // the previous one, see the timeOn element):
          {
            "shape":"cross",
            "thetaX":0,
            "thetaY":10,
            "widthThetaX":6,
            "widthThetaY":2,
            "luminance":0.5,
            "timeOn":0.070,
            "timeOff":0.600
          }
        ]
      }

See worldDataMaker.cpp's method void readLuminanceFile(void) for a way
to consume the above in a c++ program.

A file containing JSON similar to the above should be written into a
file called luminances.json in the Oculomotor SpineML model directory
so that it's available when the model is run. It's consumed by the
worldDataMaker BRAHMS component.

The parameters are:

shape: Either "cross" or "rectangle"

thetaX: The elevation of the luminance obtained by rotating the given
amount (in degrees) about the X axis in a right handed Cartesian
coordinate system. A positive thetaX leads to a positive elevation
above the horizon.

thetaY: The azimuth of the luminance obtained by rotating the given
amount (in degrees) about the Y axis. A negative value for thetaY
gives an azimuth to the right of the meridian.

widthThetaX: if shape is "rectangle" then this is the height of the
rectangle in degrees. If shape is "cross", then this is the length of
the bars making up the cross.

widthThetaY: If rectangle, this is the rectangl ewidth, if cross, then
this is the width of the bars making up the cross.

luminance: The brightness/intensity of the luminance in arbitrary
units.

timeOn: The time, in seconds at which the luminance becomes active.

timeOff: The time, in seconds at which the luminance becomes inactive.

timeOn and TimeOff can clearly be used to create a dynamic environment
with luminances appearing and disappearing during the course of a
simulation run.

WorldFrame
----------

Each luminance is pushed back onto the WorldFrame::luminanceSeries
list at the start of a simulation.

During the simulation, at each timestep, the simulation can call

WorldFrame::setLuminanceThetaMap(simtime)

where simtime is the current simulation time in seconds.

WorldFrame::setLuminanceThetaMap runs through each member of
luminanceSeries and if illuminated, writes it into
WorldFrame::luminanceThetaMap. Note that if WorldFrame::blurMode is
set true, then the luminance is blurred out at this point. If the
luminance is no longer illuminated, then it "unapplies it" (including
any Gaussian blur applied).

WorldFrame::luminanceThetaMap is 50x50 and each element contains the
luminance value.

At the end of WorldFrame::setLuminanceThetaMap,
WorldFrame::luminanceThetaMap is transformed into
WorldFrame::luminanceCoords, which contains the same luminances, but
in Cartesian coordinates.

The shape of the screen (WorldFrame::screenShape), and its distance
from the eye (WorldFrame::distanceToScreen) are used to calculate the
Cartesian x,y,z coordinates of the luminance. These x,y,z coordinates
are stored in a 2500 row matrix with 4 columns. x,y,z are stored in
the first 3 columns; the 4th contains the luminance value.

It is WorldFrame::luminanceCoords which is the data passed to the
EyeFrame class.

EyeFrame
--------

First note that the locations of the neurons in the eye - the ones
which will actually be activated by the incident light are generated
once, when the EyeFrame object is instantiated - see
EyeFrame::generateNeuronThetaCoords. This creates two data attributes
each of which has two columns; thetaX and thetaY; and 50x50 rows
EyeFrame::preciseNeuronThetaCoords contains floating point thetaX and
thetaY and these are then rounded and stored in
EyeFrame::pixelNeuronThetaCoords.

Now, we're still in the same timestep during which
WorldFrame::setLuminanceThetaMap() was called. We can now set the
eye's current rotational location using EyeFrame::setOffset() (passing
in Euler angles, as generated by the biomechanical eye model) and then
we can set the eye's field of view with:

EyeFrame::setEyeField(WorldFrame::luminanceCoords)

This makes a copy of the WorldFrame::luminanceCoords, storing the copy
in EyeFrame::luminanceCartesianCoords. It then applies the transform
from the world coordinates into the eye frame, based on the eye's
rotation which was set with EyeFrame::setOffset. This transform
updates the content of EyeFrame::luminanceCartesianCoords.

Now EyeFrame::setEyeField calls
EyeFrame::luminanceCartesianCoordsToThetaMap() which moves the
information stored in luminanceCartesianCoords into
EyeFrame::luminanceMap, which is in thetaX,thetaY coordinates.

Finally, EyeFrame::setEyeField calls EyeFrame::populateCorticalSheet()
which transforms EyeFrame::luminanceMap into
EyeFrame::corticalSheet. It does so by looping through
EyeFrame::pixelNeuronThetaCoordinates, generating cort_r and
cort_theta from this index, and then populating
EyeFrame::corticalSheet(cort_theta, cort_r) with the correct value
from EyeFrame::luminanceMap.

To change the field of view which the cortical sheet covers, change
EyeFrame::fieldOfView.
